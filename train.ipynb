{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from load_data import load_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN特征提取器\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.fc1(x.squeeze(0).T))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Graph Structure...\n",
      "1723\n",
      "Loading Nodes Features...\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "graph_seq = 6\n",
    "signal_len = 1000\n",
    "all_data = load_graph_data(data_dir, graph_seq, signal_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 M，确保 PSD\n",
    "class GraphDenoisingModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, num_nodes, beta):\n",
    "        super().__init__()\n",
    "        self.cnn = CNNFeatureExtractor(input_dim, feature_dim)  # CNN 提取特征\n",
    "        self.Q = torch.nn.Parameter(torch.randn(feature_dim, feature_dim))  # 训练 Q 确保 M 是 PSD\n",
    "        self.beta = beta\n",
    "        self.num_nodes = num_nodes\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def compute_M(self):\n",
    "        \"\"\" M = Q Q^T 确保 PSD \"\"\"\n",
    "        return torch.matmul(self.Q, self.Q.T)\n",
    "\n",
    "    def compute_distance(self, f):\n",
    "        \"\"\" 计算 d_ij = (f_i - f_j)^T M (f_i - f_j) \"\"\"\n",
    "        M = self.compute_M()\n",
    "        diff = f.unsqueeze(1) - f.unsqueeze(0)  # (N, N, d)\n",
    "        dists = torch.einsum('bnd,dd,bnd->bn', diff, M, diff)  # 计算 (fi - fj)^T M (fi - fj)\n",
    "        return dists\n",
    "\n",
    "    def compute_weights(self, dists):\n",
    "        \"\"\" 计算边权重 w_{i,j} = β_i β_j exp(-d_ij) \"\"\"\n",
    "        weights = torch.exp(-dists)  # 计算 exp(-d_ij)\n",
    "        signs = self.beta.unsqueeze(1) * self.beta.unsqueeze(0)  # 计算 β_i * β_j\n",
    "        return signs * weights  # 保证符号符合平衡图\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x.float()\n",
    "        x = x + 0.1 * torch.randn_like(x)\n",
    "        x = self.cnn(x.permute(1, 0).unsqueeze(0))  # CNN 提取特征 f_i\n",
    "        dists = self.compute_distance(x)  # 计算距离 d_{i,j}\n",
    "        weights = self.compute_weights(dists)  # 计算 w_{i,j}\n",
    "        \n",
    "        # 计算拉普拉斯矩阵 Lb\n",
    "        degree = torch.diag(weights.sum(dim=1))\n",
    "        Lb = degree - weights\n",
    "        \n",
    "        return Lb, x\n",
    "\n",
    "    def optimize_beta(self, data):\n",
    "        \"\"\" 迭代优化 β \"\"\"\n",
    "        num_nodes = self.num_nodes\n",
    "        edge_index = data.edge_index\n",
    "        x = data.x.float()\n",
    "        Lb , _ = self.forward(data)\n",
    "        origin_loss = torch.matmul(x.T, torch.matmul(Lb, x)).mean()\n",
    "        \n",
    "        for i in range(num_nodes):\n",
    "            connected_nodes = edge_index[1][edge_index[0] == i]\n",
    "            if len(connected_nodes) == 0:\n",
    "                continue\n",
    "            \n",
    "            x = data.x.float()\n",
    "            \n",
    "            self.beta[i] *= -1\n",
    "            updated_Lb, _ = self.forward(data)\n",
    "            updated_loss = torch.matmul(x.T, torch.matmul(updated_Lb, x)).mean()\n",
    "            if updated_loss > origin_loss:\n",
    "                self.beta[i] *= -1\n",
    "            else:\n",
    "                origin_loss = updated_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\" 训练 CNN + M，优化 β \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        Lb, x_pred = self.forward(data)\n",
    "\n",
    "        # 计算损失\n",
    "        x = data.x.float()\n",
    "        loss_denoising = F.mse_loss(x_pred, x)\n",
    "        # loss_GLR = torch.matmul(x.T, torch.matmul(Lb, x)).mean()\n",
    "        \n",
    "        loss = loss_denoising # + 0.1 * loss_GLR\n",
    "        loss.backward()  # 反向传播\n",
    "        self.optimizer.step()  # 更新 CNN 和 M\n",
    "\n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:33<00:00, 110.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1178.5118651288785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:34<00:00, 110.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1178.372565959952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:39<00:00, 103.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1178.8112490776589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:37<00:00, 106.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1178.3734847616106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:40<00:00, 103.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1178.3734074368256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:37<00:00, 106.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1178.3738368759314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:40<00:00, 102.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1178.3705490850152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:37<00:00, 106.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1178.3703957567236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:36<00:00, 107.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1178.3723926905188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10356/10356 [01:36<00:00, 107.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1178.3741416454154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2620/10356 [06:31<19:14,  6.70it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_beta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 62\u001b[0m, in \u001b[0;36mGraphDenoisingModel.optimize_beta\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta[i] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     origin_loss \u001b[38;5;241m=\u001b[39m updated_loss\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_nodes = all_data[0].x.shape[0]\n",
    "input_dim = all_data[0].x.shape[1]\n",
    "feature_dim = signal_len\n",
    "beta = scipy.io.loadmat('./results/cluster_labels.mat')['cluster_labels'][0]\n",
    "beta = torch.tensor(list(beta) * graph_seq, dtype=torch.float32).to(device)\n",
    "model = GraphDenoisingModel(input_dim, feature_dim, num_nodes, beta).to(device)\n",
    "train_loader = DataLoader(all_data, batch_size=1, shuffle=True)\n",
    "for epoch in range(100):\n",
    "    loss = 0.0\n",
    "    for data in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        loss += model.train_step(data) / len(all_data)\n",
    "    print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "    if epoch % 10 == 9:\n",
    "        for data in tqdm(train_loader):\n",
    "            if random.random() < 0.1:\n",
    "                model.optimize_beta(data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
